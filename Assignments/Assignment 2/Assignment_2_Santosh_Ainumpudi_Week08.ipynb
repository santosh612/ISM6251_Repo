{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ca6218a",
   "metadata": {},
   "source": [
    "# Santosh Ainumpudi -U68091846"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa4e6de",
   "metadata": {},
   "source": [
    "# Parkinsons Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c9e6e",
   "metadata": {},
   "source": [
    "My main analysis from this dataset is to differentiate between healthy individuals and those with parkinsons disease (PD). This is indicated by the \"status\" column, which has a value of 0 for healthy individuals and 1 for those with parkinsons disease (PD)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a9fd7a",
   "metadata": {},
   "source": [
    "This dataset contains voice measurements from 31 individuals, 23 of whom have Parkinson's disease (PD). Each row represents a different voice recording, identified by the name of the individual. The columns correspond to various voice measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6b917",
   "metadata": {},
   "source": [
    "Attribute Information:\n",
    "\n",
    "\n",
    "1.Name                                \n",
    "ASCII subject name and recording number\n",
    "\n",
    "2.MDVP:Fo(Hz)                         \n",
    "Average vocal fundamental frequency\n",
    "\n",
    "3.MDVP:Fhi(Hz)                        \n",
    "Maximum vocal fundamental frequency\n",
    "\n",
    "4.MDVP:Flo(Hz)                        \n",
    "Minimum vocal fundamental frequency\n",
    "\n",
    "5.MDVP:Jitter(%) , MDVP:Jitter(Abs) ,MDVP:RAP , MDVP:PPQ , Jitter:DDP\n",
    "Several measures of variation in fundamental frequency\n",
    "\n",
    "6.MDVP:Shimmer , MDVP:Shimmer(dB) , Shimmer:APQ3 , Shimmer:APQ5 , MDVP:APQ , Shimmer:DDA\n",
    "Several measures of variation in amplitude\n",
    "\n",
    "7.NHR , HNR\n",
    "Two measures of ratio of noise to tonal components in the voice\n",
    "\n",
    "8.status                              \n",
    "Health status of the subject (one) - Parkinson's, (zero) - healthy\n",
    "\n",
    "9.RPDE , D2                           \n",
    "Two nonlinear dynamical complexity measures\n",
    "\n",
    "10.DFA                                \n",
    "Signal fractal scaling exponent\n",
    "\n",
    "11.spread1 , spread2 , PPE            \n",
    "Three nonlinear measures of fundamental frequency variation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcba201",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d553b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7781e5",
   "metadata": {},
   "source": [
    "# Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95838590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('parkinsons.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63948d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phon_R01_S01_1</td>\n",
       "      <td>119.992</td>\n",
       "      <td>157.302</td>\n",
       "      <td>74.997</td>\n",
       "      <td>0.00784</td>\n",
       "      <td>0.00007</td>\n",
       "      <td>0.00370</td>\n",
       "      <td>0.00554</td>\n",
       "      <td>0.01109</td>\n",
       "      <td>0.04374</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06545</td>\n",
       "      <td>0.02211</td>\n",
       "      <td>21.033</td>\n",
       "      <td>1</td>\n",
       "      <td>0.414783</td>\n",
       "      <td>0.815285</td>\n",
       "      <td>-4.813031</td>\n",
       "      <td>0.266482</td>\n",
       "      <td>2.301442</td>\n",
       "      <td>0.284654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phon_R01_S01_2</td>\n",
       "      <td>122.400</td>\n",
       "      <td>148.650</td>\n",
       "      <td>113.819</td>\n",
       "      <td>0.00968</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.00696</td>\n",
       "      <td>0.01394</td>\n",
       "      <td>0.06134</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09403</td>\n",
       "      <td>0.01929</td>\n",
       "      <td>19.085</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458359</td>\n",
       "      <td>0.819521</td>\n",
       "      <td>-4.075192</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>2.486855</td>\n",
       "      <td>0.368674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phon_R01_S01_3</td>\n",
       "      <td>116.682</td>\n",
       "      <td>131.111</td>\n",
       "      <td>111.555</td>\n",
       "      <td>0.01050</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00544</td>\n",
       "      <td>0.00781</td>\n",
       "      <td>0.01633</td>\n",
       "      <td>0.05233</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08270</td>\n",
       "      <td>0.01309</td>\n",
       "      <td>20.651</td>\n",
       "      <td>1</td>\n",
       "      <td>0.429895</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-4.443179</td>\n",
       "      <td>0.311173</td>\n",
       "      <td>2.342259</td>\n",
       "      <td>0.332634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phon_R01_S01_4</td>\n",
       "      <td>116.676</td>\n",
       "      <td>137.871</td>\n",
       "      <td>111.366</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.00502</td>\n",
       "      <td>0.00698</td>\n",
       "      <td>0.01505</td>\n",
       "      <td>0.05492</td>\n",
       "      <td>...</td>\n",
       "      <td>0.08771</td>\n",
       "      <td>0.01353</td>\n",
       "      <td>20.644</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434969</td>\n",
       "      <td>0.819235</td>\n",
       "      <td>-4.117501</td>\n",
       "      <td>0.334147</td>\n",
       "      <td>2.405554</td>\n",
       "      <td>0.368975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phon_R01_S01_5</td>\n",
       "      <td>116.014</td>\n",
       "      <td>141.781</td>\n",
       "      <td>110.655</td>\n",
       "      <td>0.01284</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00655</td>\n",
       "      <td>0.00908</td>\n",
       "      <td>0.01966</td>\n",
       "      <td>0.06425</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10470</td>\n",
       "      <td>0.01767</td>\n",
       "      <td>19.649</td>\n",
       "      <td>1</td>\n",
       "      <td>0.417356</td>\n",
       "      <td>0.823484</td>\n",
       "      <td>-3.747787</td>\n",
       "      <td>0.234513</td>\n",
       "      <td>2.332180</td>\n",
       "      <td>0.410335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n",
       "1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n",
       "2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n",
       "3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n",
       "4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n",
       "\n",
       "   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n",
       "0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n",
       "1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n",
       "2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n",
       "3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n",
       "4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n",
       "\n",
       "   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n",
       "0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n",
       "1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n",
       "2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n",
       "3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n",
       "4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n",
       "\n",
       "    spread2        D2       PPE  \n",
       "0  0.266482  2.301442  0.284654  \n",
       "1  0.335590  2.486855  0.368674  \n",
       "2  0.311173  2.342259  0.332634  \n",
       "3  0.334147  2.405554  0.368975  \n",
       "4  0.234513  2.332180  0.410335  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438e31ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 24 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   name              195 non-null    object \n",
      " 1   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 2   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 3   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 4   MDVP:Jitter(%)    195 non-null    float64\n",
      " 5   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 6   MDVP:RAP          195 non-null    float64\n",
      " 7   MDVP:PPQ          195 non-null    float64\n",
      " 8   Jitter:DDP        195 non-null    float64\n",
      " 9   MDVP:Shimmer      195 non-null    float64\n",
      " 10  MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 11  Shimmer:APQ3      195 non-null    float64\n",
      " 12  Shimmer:APQ5      195 non-null    float64\n",
      " 13  MDVP:APQ          195 non-null    float64\n",
      " 14  Shimmer:DDA       195 non-null    float64\n",
      " 15  NHR               195 non-null    float64\n",
      " 16  HNR               195 non-null    float64\n",
      " 17  status            195 non-null    int64  \n",
      " 18  RPDE              195 non-null    float64\n",
      " 19  DFA               195 non-null    float64\n",
      " 20  spread1           195 non-null    float64\n",
      " 21  spread2           195 non-null    float64\n",
      " 22  D2                195 non-null    float64\n",
      " 23  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1), object(1)\n",
      "memory usage: 36.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f488d27",
   "metadata": {},
   "source": [
    "The target variable is the \"status\" column, which is an integer indicating the presence or absence of Parkinson's disease in the patient. The input variables are all the other columns except for the \"name\" column, which just contains the name of the patient and is not relevant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c02eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('name', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ee63f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 195 entries, 0 to 194\n",
      "Data columns (total 23 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   MDVP:Fo(Hz)       195 non-null    float64\n",
      " 1   MDVP:Fhi(Hz)      195 non-null    float64\n",
      " 2   MDVP:Flo(Hz)      195 non-null    float64\n",
      " 3   MDVP:Jitter(%)    195 non-null    float64\n",
      " 4   MDVP:Jitter(Abs)  195 non-null    float64\n",
      " 5   MDVP:RAP          195 non-null    float64\n",
      " 6   MDVP:PPQ          195 non-null    float64\n",
      " 7   Jitter:DDP        195 non-null    float64\n",
      " 8   MDVP:Shimmer      195 non-null    float64\n",
      " 9   MDVP:Shimmer(dB)  195 non-null    float64\n",
      " 10  Shimmer:APQ3      195 non-null    float64\n",
      " 11  Shimmer:APQ5      195 non-null    float64\n",
      " 12  MDVP:APQ          195 non-null    float64\n",
      " 13  Shimmer:DDA       195 non-null    float64\n",
      " 14  NHR               195 non-null    float64\n",
      " 15  HNR               195 non-null    float64\n",
      " 16  status            195 non-null    int64  \n",
      " 17  RPDE              195 non-null    float64\n",
      " 18  DFA               195 non-null    float64\n",
      " 19  spread1           195 non-null    float64\n",
      " 20  spread2           195 non-null    float64\n",
      " 21  D2                195 non-null    float64\n",
      " 22  PPE               195 non-null    float64\n",
      "dtypes: float64(22), int64(1)\n",
      "memory usage: 35.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe539795",
   "metadata": {},
   "source": [
    "Most of the columns are of type float64 i.e 22 of them , with one column (status) of type int64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "239e820b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MDVP:Fo(Hz)</th>\n",
       "      <th>MDVP:Fhi(Hz)</th>\n",
       "      <th>MDVP:Flo(Hz)</th>\n",
       "      <th>MDVP:Jitter(%)</th>\n",
       "      <th>MDVP:Jitter(Abs)</th>\n",
       "      <th>MDVP:RAP</th>\n",
       "      <th>MDVP:PPQ</th>\n",
       "      <th>Jitter:DDP</th>\n",
       "      <th>MDVP:Shimmer</th>\n",
       "      <th>MDVP:Shimmer(dB)</th>\n",
       "      <th>...</th>\n",
       "      <th>Shimmer:DDA</th>\n",
       "      <th>NHR</th>\n",
       "      <th>HNR</th>\n",
       "      <th>status</th>\n",
       "      <th>RPDE</th>\n",
       "      <th>DFA</th>\n",
       "      <th>spread1</th>\n",
       "      <th>spread2</th>\n",
       "      <th>D2</th>\n",
       "      <th>PPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>195.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>154.228641</td>\n",
       "      <td>197.104918</td>\n",
       "      <td>116.324631</td>\n",
       "      <td>0.006220</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.003446</td>\n",
       "      <td>0.009920</td>\n",
       "      <td>0.029709</td>\n",
       "      <td>0.282251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046993</td>\n",
       "      <td>0.024847</td>\n",
       "      <td>21.885974</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.498536</td>\n",
       "      <td>0.718099</td>\n",
       "      <td>-5.684397</td>\n",
       "      <td>0.226510</td>\n",
       "      <td>2.381826</td>\n",
       "      <td>0.206552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>41.390065</td>\n",
       "      <td>91.491548</td>\n",
       "      <td>43.521413</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.008903</td>\n",
       "      <td>0.018857</td>\n",
       "      <td>0.194877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030459</td>\n",
       "      <td>0.040418</td>\n",
       "      <td>4.425764</td>\n",
       "      <td>0.431878</td>\n",
       "      <td>0.103942</td>\n",
       "      <td>0.055336</td>\n",
       "      <td>1.090208</td>\n",
       "      <td>0.083406</td>\n",
       "      <td>0.382799</td>\n",
       "      <td>0.090119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>88.333000</td>\n",
       "      <td>102.145000</td>\n",
       "      <td>65.476000</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.009540</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>8.441000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.256570</td>\n",
       "      <td>0.574282</td>\n",
       "      <td>-7.964984</td>\n",
       "      <td>0.006274</td>\n",
       "      <td>1.423287</td>\n",
       "      <td>0.044539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>117.572000</td>\n",
       "      <td>134.862500</td>\n",
       "      <td>84.291000</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.001660</td>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.004985</td>\n",
       "      <td>0.016505</td>\n",
       "      <td>0.148500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.005925</td>\n",
       "      <td>19.198000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.421306</td>\n",
       "      <td>0.674758</td>\n",
       "      <td>-6.450096</td>\n",
       "      <td>0.174351</td>\n",
       "      <td>2.099125</td>\n",
       "      <td>0.137451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>148.790000</td>\n",
       "      <td>175.829000</td>\n",
       "      <td>104.315000</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>0.221000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038360</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>22.085000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.495954</td>\n",
       "      <td>0.722254</td>\n",
       "      <td>-5.720868</td>\n",
       "      <td>0.218885</td>\n",
       "      <td>2.361532</td>\n",
       "      <td>0.194052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>182.769000</td>\n",
       "      <td>224.205500</td>\n",
       "      <td>140.018500</td>\n",
       "      <td>0.007365</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.003835</td>\n",
       "      <td>0.003955</td>\n",
       "      <td>0.011505</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060795</td>\n",
       "      <td>0.025640</td>\n",
       "      <td>25.075500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.587562</td>\n",
       "      <td>0.761881</td>\n",
       "      <td>-5.046192</td>\n",
       "      <td>0.279234</td>\n",
       "      <td>2.636456</td>\n",
       "      <td>0.252980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>260.105000</td>\n",
       "      <td>592.030000</td>\n",
       "      <td>239.170000</td>\n",
       "      <td>0.033160</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.021440</td>\n",
       "      <td>0.019580</td>\n",
       "      <td>0.064330</td>\n",
       "      <td>0.119080</td>\n",
       "      <td>1.302000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169420</td>\n",
       "      <td>0.314820</td>\n",
       "      <td>33.047000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685151</td>\n",
       "      <td>0.825288</td>\n",
       "      <td>-2.434031</td>\n",
       "      <td>0.450493</td>\n",
       "      <td>3.671155</td>\n",
       "      <td>0.527367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n",
       "count   195.000000    195.000000    195.000000      195.000000   \n",
       "mean    154.228641    197.104918    116.324631        0.006220   \n",
       "std      41.390065     91.491548     43.521413        0.004848   \n",
       "min      88.333000    102.145000     65.476000        0.001680   \n",
       "25%     117.572000    134.862500     84.291000        0.003460   \n",
       "50%     148.790000    175.829000    104.315000        0.004940   \n",
       "75%     182.769000    224.205500    140.018500        0.007365   \n",
       "max     260.105000    592.030000    239.170000        0.033160   \n",
       "\n",
       "       MDVP:Jitter(Abs)    MDVP:RAP    MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  \\\n",
       "count        195.000000  195.000000  195.000000  195.000000    195.000000   \n",
       "mean           0.000044    0.003306    0.003446    0.009920      0.029709   \n",
       "std            0.000035    0.002968    0.002759    0.008903      0.018857   \n",
       "min            0.000007    0.000680    0.000920    0.002040      0.009540   \n",
       "25%            0.000020    0.001660    0.001860    0.004985      0.016505   \n",
       "50%            0.000030    0.002500    0.002690    0.007490      0.022970   \n",
       "75%            0.000060    0.003835    0.003955    0.011505      0.037885   \n",
       "max            0.000260    0.021440    0.019580    0.064330      0.119080   \n",
       "\n",
       "       MDVP:Shimmer(dB)  ...  Shimmer:DDA         NHR         HNR      status  \\\n",
       "count        195.000000  ...   195.000000  195.000000  195.000000  195.000000   \n",
       "mean           0.282251  ...     0.046993    0.024847   21.885974    0.753846   \n",
       "std            0.194877  ...     0.030459    0.040418    4.425764    0.431878   \n",
       "min            0.085000  ...     0.013640    0.000650    8.441000    0.000000   \n",
       "25%            0.148500  ...     0.024735    0.005925   19.198000    1.000000   \n",
       "50%            0.221000  ...     0.038360    0.011660   22.085000    1.000000   \n",
       "75%            0.350000  ...     0.060795    0.025640   25.075500    1.000000   \n",
       "max            1.302000  ...     0.169420    0.314820   33.047000    1.000000   \n",
       "\n",
       "             RPDE         DFA     spread1     spread2          D2         PPE  \n",
       "count  195.000000  195.000000  195.000000  195.000000  195.000000  195.000000  \n",
       "mean     0.498536    0.718099   -5.684397    0.226510    2.381826    0.206552  \n",
       "std      0.103942    0.055336    1.090208    0.083406    0.382799    0.090119  \n",
       "min      0.256570    0.574282   -7.964984    0.006274    1.423287    0.044539  \n",
       "25%      0.421306    0.674758   -6.450096    0.174351    2.099125    0.137451  \n",
       "50%      0.495954    0.722254   -5.720868    0.218885    2.361532    0.194052  \n",
       "75%      0.587562    0.761881   -5.046192    0.279234    2.636456    0.252980  \n",
       "max      0.685151    0.825288   -2.434031    0.450493    3.671155    0.527367  \n",
       "\n",
       "[8 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "640a1f61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MDVP:Fo(Hz)', 'MDVP:Fhi(Hz)', 'MDVP:Flo(Hz)', 'MDVP:Jitter(%)',\n",
       "       'MDVP:Jitter(Abs)', 'MDVP:RAP', 'MDVP:PPQ', 'Jitter:DDP',\n",
       "       'MDVP:Shimmer', 'MDVP:Shimmer(dB)', 'Shimmer:APQ3', 'Shimmer:APQ5',\n",
       "       'MDVP:APQ', 'Shimmer:DDA', 'NHR', 'HNR', 'status', 'RPDE', 'DFA',\n",
       "       'spread1', 'spread2', 'D2', 'PPE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce65c001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(195, 23)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "754ada6f",
   "metadata": {},
   "source": [
    "# Find the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0387a8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MDVP:Fo(Hz)         0\n",
       "MDVP:Fhi(Hz)        0\n",
       "MDVP:Flo(Hz)        0\n",
       "MDVP:Jitter(%)      0\n",
       "MDVP:Jitter(Abs)    0\n",
       "MDVP:RAP            0\n",
       "MDVP:PPQ            0\n",
       "Jitter:DDP          0\n",
       "MDVP:Shimmer        0\n",
       "MDVP:Shimmer(dB)    0\n",
       "Shimmer:APQ3        0\n",
       "Shimmer:APQ5        0\n",
       "MDVP:APQ            0\n",
       "Shimmer:DDA         0\n",
       "NHR                 0\n",
       "HNR                 0\n",
       "status              0\n",
       "RPDE                0\n",
       "DFA                 0\n",
       "spread1             0\n",
       "spread2             0\n",
       "D2                  0\n",
       "PPE                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8c180",
   "metadata": {},
   "source": [
    "The df.isnull().sum() method returns the number of missing values in each column of the DataFrame. In this case, all columns have zero missing values, which indicates that the data is complete and ready for processing. Therefore, we can proceed with our analysis without having to impute or drop any missing values.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3625eda",
   "metadata": {},
   "source": [
    "# Split into Features and Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf0be9",
   "metadata": {},
   "source": [
    "The features are the input variables that the machine learning model uses to make predictions, while the target variable is the output variable that the model is trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5baf2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['status'], axis=1)\n",
    "y = df['status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88acd51a",
   "metadata": {},
   "source": [
    "# Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f26262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b51012",
   "metadata": {},
   "source": [
    "To evaluate the performance of our model on unseen data we will split the data into training and testing sets, where 30% of the data will be used for testing, and the remaining 70% will be used for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb0b6c5",
   "metadata": {},
   "source": [
    "#### Scalling of the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5a7b30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4aa019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=sc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77b31c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f900ece4",
   "metadata": {},
   "source": [
    "# SVM Classification model with Linear Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef219dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\", probability=True)\n",
    "_ = svm_lin_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e56d8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the performance DataFrame\n",
    "performance = pd.DataFrame(columns=['model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6fb6b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Accuracy  Precision    Recall        F1\n",
       "0  svm with linear kernel  0.864407      0.875  0.954545  0.913043"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm with linear kernel\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69c4c4d7",
   "metadata": {},
   "source": [
    "# SVM Classification model with rbf Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b71113dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=4, gamma='scale', probability=True)\n",
    "_ = svm_rbf_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e155db1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    model  Accuracy  Precision    Recall        F1\n",
       "0  svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0     svm with rbf kernel  0.915254   0.897959  1.000000  0.946237"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm with rbf kernel\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96ff295",
   "metadata": {},
   "source": [
    "# SVM Classification model with Polynomial Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a633f8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\", degree=3, coef0=1, C=4, probability=True)\n",
    "_ = svm_poly_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a00fbcff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  Accuracy  Precision    Recall        F1\n",
       "0      svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0         svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0  svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_poly_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "if TP+FP == 0:\n",
    "    precision = 0\n",
    "else:\n",
    "    precision = TP/(TP+FP)\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"svm with polynomial kernel\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [precision], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e696e578",
   "metadata": {},
   "source": [
    "# SVM Classification model with Randomized Search Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17ccb634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END .......C=2, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=2, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .......C=2, gamma=1, kernel=linear;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .......C=2, gamma=1, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .......C=2, gamma=1, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .......C=2, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .......C=2, gamma=0.1, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .......C=2, gamma=0.1, kernel=poly;, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END .......C=2, gamma=0.1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .......C=2, gamma=0.1, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .........C=2, gamma=1, kernel=poly;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .........C=2, gamma=1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .........C=2, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .........C=2, gamma=1, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END .........C=2, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ......C=2, gamma=0.01, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ......C=2, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END ......C=2, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ......C=2, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ......C=2, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .......C=5, gamma=1, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END .......C=5, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .......C=5, gamma=1, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END .......C=5, gamma=1, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .......C=5, gamma=1, kernel=linear;, score=0.741 total time=   0.0s\n",
      "The best accuracy score is 0.9042328042328043\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 1, 'C': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 3\n",
    "param_grid = {'C': [1, 2, 5], \n",
    "              'gamma': [1, 0.1, 0.01],\n",
    "              'kernel': ['linear','poly']} \n",
    "  \n",
    "rand_search = RandomizedSearchCV(SVC(), param_grid, refit=True, verbose=3)\n",
    "  \n",
    "# fitting the model for randomized search\n",
    "rand_search.fit(X_train, y_train)\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a1072204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  Accuracy  Precision    Recall        F1\n",
       "0      svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0         svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0  svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0    Random search SVM Linear  0.932203   0.934783  0.977273  0.955556"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Random search SVM Linear\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614b67f",
   "metadata": {},
   "source": [
    "# SVM Classification model with Grid Search Kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25a66799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
      "[CV 1/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=1, kernel=linear;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END .......C=0.1, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, gamma=0.1, kernel=linear;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.889 total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, gamma=0.1, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, gamma=0.01, kernel=linear;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ....C=0.1, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=1, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=1, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .........C=1, gamma=1, kernel=poly;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .........C=1, gamma=1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .........C=1, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .........C=1, gamma=1, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END .........C=1, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, gamma=0.1, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .......C=1, gamma=0.1, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END ....C=1, gamma=0.01, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ......C=1, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .......C=5, gamma=1, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END .......C=5, gamma=1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .......C=5, gamma=1, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END .......C=5, gamma=1, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .......C=5, gamma=1, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .........C=5, gamma=1, kernel=poly;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .........C=5, gamma=1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .........C=5, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .........C=5, gamma=1, kernel=poly;, score=0.963 total time=   0.0s\n",
      "[CV 5/5] END .........C=5, gamma=1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END .....C=5, gamma=0.1, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END .....C=5, gamma=0.1, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .....C=5, gamma=0.1, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END .....C=5, gamma=0.1, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END .....C=5, gamma=0.1, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END .......C=5, gamma=0.1, kernel=poly;, score=0.929 total time=   0.0s\n",
      "[CV 2/5] END .......C=5, gamma=0.1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .......C=5, gamma=0.1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 4/5] END .......C=5, gamma=0.1, kernel=poly;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .......C=5, gamma=0.1, kernel=poly;, score=0.852 total time=   0.0s\n",
      "[CV 1/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.893 total time=   0.0s\n",
      "[CV 2/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END ....C=5, gamma=0.01, kernel=linear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 3/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "[CV 5/5] END ......C=5, gamma=0.01, kernel=poly;, score=0.741 total time=   0.0s\n",
      "The best accuracy score is 0.9116402116402117\n",
      "... with parameters: {'C': 5, 'gamma': 0.1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 3\n",
    "param_grid = {'C': [0.1, 1, 5], \n",
    "              'gamma': [1, 0.1, 0.01],\n",
    "              'kernel': ['linear','poly']} \n",
    "  \n",
    "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"The best {score_measure} score is {grid.best_score_}\")\n",
    "print(f\"... with parameters: {grid.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21631446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  Accuracy  Precision    Recall        F1\n",
       "0      svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0         svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0  svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0    Random search SVM Linear  0.932203   0.934783  0.977273  0.955556\n",
       "0      Grid search SVM Linear  0.949153   0.936170  1.000000  0.967033"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Grid search SVM Linear\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0296d99",
   "metadata": {},
   "source": [
    "# Logistic Regression model without Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a86c5a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "log_reg_model = LogisticRegression(penalty='none')\n",
    "_ = log_reg_model.fit(X_train, np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c478c1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  accuracy\n",
      "2        decision tree      0.90\n",
      "0  logistic regression      0.80\n",
      "1                  SVM      0.75\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'model': ['logistic regression', 'SVM', 'decision tree'], 'accuracy': [0.8, 0.75, 0.9]})\n",
    "\n",
    "# sort the DataFrame by the 'accuracy' column in descending order\n",
    "df_sorted = df.sort_values(by='accuracy', ascending=False)\n",
    "\n",
    "# print the sorted DataFrame\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf64d39b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  Accuracy  Precision    Recall        F1\n",
       "0      svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0         svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0  svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0    Random search SVM Linear  0.932203   0.934783  0.977273  0.955556\n",
       "0      Grid search SVM Linear  0.949153   0.936170  1.000000  0.967033\n",
       "0            default logistic  0.932203   0.916667  1.000000  0.956522"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_preds = log_reg_model.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"default logistic\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bdb1ff",
   "metadata": {},
   "source": [
    "# RandomizedSearch with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d94cb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l1, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l1, solver=liblinear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l1, solver=liblinear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l1, solver=liblinear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.001, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.001, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.001, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.001, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.001, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.704 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=liblinear;, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=0.001, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "The best accuracy score is 0.8537037037037039\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "30 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got elastic.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got lasso.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82407407        nan        nan        nan 0.83809524\n",
      " 0.8537037  0.8462963         nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "LR=LogisticRegression()\n",
    "kfolds = 5\n",
    "param_grid = {'C': [0.1, 1, 10,0.001], \n",
    "              \"solver\" : [ 'lbfgs', 'liblinear'],\n",
    "              \"penalty\" : ['l1','l2','lasso','elastic']} \n",
    "  \n",
    "grid = RandomizedSearchCV(LR, param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"The best {score_measure} score is {grid.best_score_}\")\n",
    "print(f\"... with parameters: {grid.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83523dd3",
   "metadata": {},
   "source": [
    "# Logistic Regression with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a78143b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0          svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0             svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0      svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0        Random search SVM Linear  0.932203   0.934783  0.977273  0.955556\n",
       "0          Grid search SVM Linear  0.949153   0.936170  1.000000  0.967033\n",
       "0                default logistic  0.932203   0.916667  1.000000  0.956522\n",
       "0  Logistic Regression Randomised  0.898305   0.895833  0.977273  0.934783"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = grid.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression Randomised\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b8a5fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "[CV 1/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.889 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.852 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=l1, solver=liblinear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.857 total time=   0.0s\n",
      "[CV 2/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.963 total time=   0.0s\n",
      "[CV 3/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 4/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.704 total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=l2, solver=liblinear;, score=0.704 total time=   0.0s\n",
      "[CV 1/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=0.1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=0.1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=1, penalty=l1, solver=liblinear;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END .C=1, penalty=l1, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END .C=1, penalty=l1, solver=liblinear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END .C=1, penalty=l1, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .C=1, penalty=l1, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.786 total time=   0.0s\n",
      "[CV 2/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.889 total time=   0.0s\n",
      "[CV 3/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .....C=1, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END .C=1, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END .C=1, penalty=l2, solver=liblinear;, score=0.889 total time=   0.0s\n",
      "[CV 3/5] END .C=1, penalty=l2, solver=liblinear;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END .C=1, penalty=l2, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END .C=1, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ....C=1, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ..C=1, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=1, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l1, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l1, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l1, solver=liblinear;, score=0.815 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l1, solver=liblinear;, score=0.889 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l1, solver=liblinear;, score=0.741 total time=   0.0s\n",
      "[CV 1/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.852 total time=   0.0s\n",
      "[CV 4/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END ....C=10, penalty=l2, solver=lbfgs;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=l2, solver=liblinear;, score=0.750 total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=l2, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=l2, solver=liblinear;, score=0.889 total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=l2, solver=liblinear;, score=0.926 total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=l2, solver=liblinear;, score=0.778 total time=   0.0s\n",
      "[CV 1/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END ...C=10, penalty=lasso, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=lasso, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 4/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 5/5] END .C=10, penalty=elastic, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 4/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 5/5] END C=10, penalty=elastic, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "75 fits failed out of a total of 120.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got lasso.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 441, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Logistic Regression supports only penalties in ['l1', 'l2', 'elasticnet', 'none'], got elastic.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.83068783 0.83809524 0.82380952        nan        nan\n",
      "        nan        nan        nan 0.84603175 0.84603175 0.83888889\n",
      "        nan        nan        nan        nan        nan 0.82407407\n",
      " 0.8462963  0.8537037         nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best accuracy score is 0.8537037037037039\n",
      "... with parameters: {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "param_grid = {'C': [0.1, 1, 10], \n",
    "              'solver' : [ 'lbfgs', 'liblinear'],\n",
    "              'penalty' : ['l1','l2','lasso','elastic']} \n",
    "  \n",
    "grid = GridSearchCV(LogisticRegression(), param_grid, refit = True, verbose = 3)\n",
    "  \n",
    "# fitting the model for grid search\n",
    "grid.fit(X_train, y_train)\n",
    "print(f\"The best {score_measure} score is {grid.best_score_}\")\n",
    "print(f\"... with parameters: {grid.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0c1ab8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0          svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0             svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0      svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0        Random search SVM Linear  0.932203   0.934783  0.977273  0.955556\n",
       "0          Grid search SVM Linear  0.949153   0.936170  1.000000  0.967033\n",
       "0                default logistic  0.932203   0.916667  1.000000  0.956522\n",
       "0  Logistic Regression Randomised  0.898305   0.895833  0.977273  0.934783\n",
       "0        Logistic Regression Grid  0.898305   0.895833  0.977273  0.934783"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = grid.predict(X_test)\n",
    "c_matrix = confusion_matrix(y_test, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Regression Grid\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206261ca",
   "metadata": {},
   "source": [
    "# Decision tree model using the randomsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5760cfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "The best accuracy score is 0.8676328502415459\n",
      "... with parameters: {'min_samples_split': 10, 'min_samples_leaf': 7, 'min_impurity_decrease': 0.0081, 'max_leaf_nodes': 199, 'max_depth': 25, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "9 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.71980676 0.74959742 0.69806763 0.72028986 0.75732689 0.83059581\n",
      " 0.75732689 0.71980676 0.75732689 0.66956522 0.71239936 0.72028986\n",
      " 0.80901771 0.72028986 0.69758454 0.72028986        nan 0.78615137\n",
      " 0.75732689 0.69806763 0.75732689 0.79371981 0.72028986 0.80901771\n",
      " 0.83800322 0.82318841 0.72705314 0.72028986        nan 0.72028986\n",
      " 0.77938808 0.86763285 0.72028986 0.72028986 0.81642512 0.72028986\n",
      " 0.75732689 0.75716586 0.82318841 0.75732689 0.72028986 0.80901771\n",
      " 0.7568438  0.72028986 0.69806763 0.7568438  0.79371981 0.79371981\n",
      " 0.81626409 0.73429952 0.77938808 0.7568438  0.80161031 0.75732689\n",
      " 0.72028986 0.69033816 0.83800322 0.72028986 0.72753623 0.75732689\n",
      " 0.72705314 0.815781   0.68293076        nan 0.72028986 0.71980676\n",
      " 0.72028986 0.72028986 0.69758454 0.72028986 0.69806763 0.71980676\n",
      " 0.80177134 0.80177134 0.69033816 0.69033816 0.80901771 0.83800322\n",
      " 0.83059581 0.81610306 0.75732689 0.75732689 0.815781   0.75732689\n",
      " 0.71239936 0.72769726 0.69774557 0.69033816 0.75732689 0.83059581\n",
      " 0.69758454 0.69758454 0.69033816 0.73429952 0.80128824 0.72028986\n",
      " 0.71980676 0.74186795 0.72028986 0.69033816]\n",
      "  warnings.warn(\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.83817664 0.85295075 0.81595442 0.77932438 0.75734636 0.90809931\n",
      " 0.75734636 0.83817664 0.75734636 0.7978022  0.82718763 0.77932438\n",
      " 0.86760277 0.76467236 0.81986162 0.78298738        nan 0.88978429\n",
      " 0.75734636 0.81595442 0.75734636 0.88608059 0.76833537 0.86760277\n",
      " 0.87501018 0.93007733 0.84558405 0.76100936        nan 0.78298738\n",
      " 0.88591779 0.94122914 0.78298738 0.76467236 0.94114774 0.78298738\n",
      " 0.75734636 0.92283272 0.91176231 0.75734636 0.76833537 0.86760277\n",
      " 0.84183964 0.78298738 0.81595442 0.84183964 0.88237688 0.88608059\n",
      " 0.97431827 0.84928775 0.92649573 0.84183964 0.86760277 0.75734636\n",
      " 0.76833537 0.80875051 0.87501018 0.76100936 0.77203907 0.75734636\n",
      " 0.84558405 0.90809931 0.79409849        nan 0.76833537 0.83817664\n",
      " 0.76833537 0.76833537 0.81986162 0.76833537 0.81595442 0.83817664\n",
      " 0.83426943 0.83426943 0.80875051 0.80508751 0.86760277 0.87501018\n",
      " 0.90809931 0.95596256 0.75734636 0.75734636 0.90809931 0.75734636\n",
      " 0.82718763 0.75734636 0.79409849 0.80875051 0.75734636 0.90809931\n",
      " 0.81986162 0.81986162 0.80875051 0.84928775 0.8971103  0.77932438\n",
      " 0.83817664 0.82714693 0.78298738 0.80508751]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,60),  \n",
    "    'min_samples_leaf': np.arange(1,50),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 200), \n",
    "    'max_depth': np.arange(1,50), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42ce92a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree random search</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0          svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0             svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0      svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0        Random search SVM Linear  0.932203   0.934783  0.977273  0.955556\n",
       "0          Grid search SVM Linear  0.949153   0.936170  1.000000  0.967033\n",
       "0                default logistic  0.932203   0.916667  1.000000  0.956522\n",
       "0  Logistic Regression Randomised  0.898305   0.895833  0.977273  0.934783\n",
       "0        Logistic Regression Grid  0.898305   0.895833  0.977273  0.934783\n",
       "0     Decision tree random search  0.864407   0.909091  0.909091  0.909091"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, rand_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision tree random search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb404ba",
   "metadata": {},
   "source": [
    "# Decision tree model using the Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c3770b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 2268 candidates, totalling 6804 fits\n",
      "The best accuracy score is 0.8380032206119163\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 15, 'max_leaf_nodes': 194, 'min_impurity_decrease': 0.0001, 'min_samples_leaf': 5, 'min_samples_split': 27}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"accuracy\"\n",
    "kfolds = 3\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(25,32),  \n",
    "    'min_samples_leaf': np.arange(3,6),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.0004, 0.0001),\n",
    "    'max_leaf_nodes': np.arange(194,200), \n",
    "    'max_depth': np.arange(15,21), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2c87c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree random search</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search DT</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0          svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0             svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0      svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0        Random search SVM Linear  0.932203   0.934783  0.977273  0.955556\n",
       "0          Grid search SVM Linear  0.949153   0.936170  1.000000  0.967033\n",
       "0                default logistic  0.932203   0.916667  1.000000  0.956522\n",
       "0  Logistic Regression Randomised  0.898305   0.895833  0.977273  0.934783\n",
       "0        Logistic Regression Grid  0.898305   0.895833  0.977273  0.934783\n",
       "0     Decision tree random search  0.864407   0.909091  0.909091  0.909091\n",
       "0                  Grid search DT  0.830508   0.904762  0.863636  0.883721"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "if TP+FP == 0:\n",
    "    precision = 0  # or precision = np.nan\n",
    "else:\n",
    "    precision = TP/(TP+FP)\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Grid search DT\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [precision], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "\n",
    "performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "77e4c55f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 model  accuracy\n",
      "2        decision tree      0.90\n",
      "0  logistic regression      0.80\n",
      "1                  SVM      0.75\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'model': ['logistic regression', 'SVM', 'decision tree'], 'accuracy': [0.8, 0.75, 0.9]})\n",
    "\n",
    "# sort the DataFrame by the 'accuracy' column in descending order\n",
    "df_sorted = df.sort_values(by='accuracy', ascending=False)\n",
    "\n",
    "# print the sorted DataFrame\n",
    "print(df_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5af8813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search DT</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree random search</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            model  Accuracy  Precision    Recall        F1\n",
       "0                  Grid search DT  0.830508   0.904762  0.863636  0.883721\n",
       "0          svm with linear kernel  0.864407   0.875000  0.954545  0.913043\n",
       "0     Decision tree random search  0.864407   0.909091  0.909091  0.909091\n",
       "0  Logistic Regression Randomised  0.898305   0.895833  0.977273  0.934783\n",
       "0        Logistic Regression Grid  0.898305   0.895833  0.977273  0.934783\n",
       "0             svm with rbf kernel  0.915254   0.897959  1.000000  0.946237\n",
       "0      svm with polynomial kernel  0.932203   0.916667  1.000000  0.956522\n",
       "0        Random search SVM Linear  0.932203   0.934783  0.977273  0.955556\n",
       "0                default logistic  0.932203   0.916667  1.000000  0.956522\n",
       "0          Grid search SVM Linear  0.949153   0.936170  1.000000  0.967033"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by =['Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da201ee",
   "metadata": {},
   "source": [
    "# Neural Network with MLPClassifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951aff10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b1558087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "300cb639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 994 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "ann = MLPClassifier(hidden_layer_sizes=(60,50,40), solver='adam', max_iter=200)\n",
    "_ = ann.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d53bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = ann.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6a86e721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.86        15\n",
      "           1       0.93      0.98      0.96        44\n",
      "\n",
      "    accuracy                           0.93        59\n",
      "   macro avg       0.93      0.89      0.91        59\n",
      "weighted avg       0.93      0.93      0.93        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbac23ae",
   "metadata": {},
   "source": [
    "# With RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "907d1152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.001, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (60, 40, 20), 'alpha': 1, 'activation': 'tanh'}\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b0c0a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        15\n",
      "           1       0.96      1.00      0.98        44\n",
      "\n",
      "    accuracy                           0.97        59\n",
      "   macro avg       0.98      0.93      0.95        59\n",
      "weighted avg       0.97      0.97      0.97        59\n",
      "\n",
      "Wall time: 8.12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "693c14d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree random search</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search DT</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Randomized search DT</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0               svm with linear kernel  0.864407   0.875000  0.954545   \n",
       "0                  svm with rbf kernel  0.915254   0.897959  1.000000   \n",
       "0           svm with polynomial kernel  0.932203   0.916667  1.000000   \n",
       "0             Random search SVM Linear  0.932203   0.934783  0.977273   \n",
       "0               Grid search SVM Linear  0.949153   0.936170  1.000000   \n",
       "0                     default logistic  0.932203   0.916667  1.000000   \n",
       "0       Logistic Regression Randomised  0.898305   0.895833  0.977273   \n",
       "0             Logistic Regression Grid  0.898305   0.895833  0.977273   \n",
       "0          Decision tree random search  0.864407   0.909091  0.909091   \n",
       "0                       Grid search DT  0.830508   0.904762  0.863636   \n",
       "0  Neural Network Randomized search DT  0.966102   0.956522  1.000000   \n",
       "\n",
       "         F1  \n",
       "0  0.913043  \n",
       "0  0.946237  \n",
       "0  0.956522  \n",
       "0  0.955556  \n",
       "0  0.967033  \n",
       "0  0.956522  \n",
       "0  0.934783  \n",
       "0  0.934783  \n",
       "0  0.909091  \n",
       "0  0.883721  \n",
       "0  0.977778  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "if TP+FP == 0:\n",
    "    precision = 0  # or precision = np.nan\n",
    "else:\n",
    "    precision = TP/(TP+FP)\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network Randomized search DT\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [precision], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db667530",
   "metadata": {},
   "source": [
    "# With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "84969c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "{'activation': 'tanh', 'alpha': 0.5, 'hidden_layer_sizes': (70,), 'learning_rate': 'adaptive', 'learning_rate_init': 0.15, 'max_iter': 5000, 'solver': 'adam'}\n",
      "Wall time: 23.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (30,), (50,), (70,), (90,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['adam'],\n",
    "    'alpha': [.5, .7, 1],\n",
    "    'learning_rate': ['adaptive', 'invscaling'],\n",
    "    'learning_rate_init': [0.005, 0.01, 0.15],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e33cbf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90        15\n",
      "           1       0.96      0.98      0.97        44\n",
      "\n",
      "    accuracy                           0.95        59\n",
      "   macro avg       0.94      0.92      0.93        59\n",
      "weighted avg       0.95      0.95      0.95        59\n",
      "\n",
      "Wall time: 12.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = bestRecallTree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e6798fe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with linear kernel</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with rbf kernel</td>\n",
       "      <td>0.915254</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm with polynomial kernel</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random search SVM Linear</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.955556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search SVM Linear</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.936170</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>default logistic</td>\n",
       "      <td>0.932203</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Randomised</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression Grid</td>\n",
       "      <td>0.898305</td>\n",
       "      <td>0.895833</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.934783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision tree random search</td>\n",
       "      <td>0.864407</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.909091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Grid search DT</td>\n",
       "      <td>0.830508</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.883721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Randomized search DT</td>\n",
       "      <td>0.966102</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Grid search DT</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.977273</td>\n",
       "      <td>0.966292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0               svm with linear kernel  0.864407   0.875000  0.954545   \n",
       "0                  svm with rbf kernel  0.915254   0.897959  1.000000   \n",
       "0           svm with polynomial kernel  0.932203   0.916667  1.000000   \n",
       "0             Random search SVM Linear  0.932203   0.934783  0.977273   \n",
       "0               Grid search SVM Linear  0.949153   0.936170  1.000000   \n",
       "0                     default logistic  0.932203   0.916667  1.000000   \n",
       "0       Logistic Regression Randomised  0.898305   0.895833  0.977273   \n",
       "0             Logistic Regression Grid  0.898305   0.895833  0.977273   \n",
       "0          Decision tree random search  0.864407   0.909091  0.909091   \n",
       "0                       Grid search DT  0.830508   0.904762  0.863636   \n",
       "0  Neural Network Randomized search DT  0.966102   0.956522  1.000000   \n",
       "0        Neural Network Grid search DT  0.949153   0.955556  0.977273   \n",
       "\n",
       "         F1  \n",
       "0  0.913043  \n",
       "0  0.946237  \n",
       "0  0.956522  \n",
       "0  0.955556  \n",
       "0  0.967033  \n",
       "0  0.956522  \n",
       "0  0.934783  \n",
       "0  0.934783  \n",
       "0  0.909091  \n",
       "0  0.883721  \n",
       "0  0.977778  \n",
       "0  0.966292  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "\n",
    "if TP+FP == 0:\n",
    "    precision = 0  # or precision = np.nan\n",
    "else:\n",
    "    precision = TP/(TP+FP)\n",
    "\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network Grid search DT\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [precision], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d6158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49581c98",
   "metadata": {},
   "source": [
    "# Using Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab7b2ff",
   "metadata": {},
   "source": [
    "# Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c783fc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1f2b696d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(136, 22)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "83c9e2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 112 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# create model stucture\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Input(shape=22))\n",
    "model.add(keras.layers.Dense(22, activation='relu'))\n",
    "model.add(keras.layers.Dense(22, activation='relu'))\n",
    "model.add(keras.layers.Dense(22, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid')) # final layer, 10 categories\n",
    "\n",
    "\n",
    "# compile\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# if you want to overide the defaults for the optimizer....\n",
    "#adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "#model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0d898bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 408ms/step - loss: 0.7495 - accuracy: 0.2868 - val_loss: 0.7146 - val_accuracy: 0.3898\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.7264 - accuracy: 0.3456 - val_loss: 0.7002 - val_accuracy: 0.4746\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 65ms/step - loss: 0.7051 - accuracy: 0.4265 - val_loss: 0.6866 - val_accuracy: 0.4915\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 57ms/step - loss: 0.6865 - accuracy: 0.5441 - val_loss: 0.6737 - val_accuracy: 0.6102\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.6697 - accuracy: 0.6471 - val_loss: 0.6615 - val_accuracy: 0.6780\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6538 - accuracy: 0.7279 - val_loss: 0.6500 - val_accuracy: 0.7119\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6389 - accuracy: 0.7426 - val_loss: 0.6389 - val_accuracy: 0.7627\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6246 - accuracy: 0.7868 - val_loss: 0.6281 - val_accuracy: 0.7966\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.6115 - accuracy: 0.8162 - val_loss: 0.6175 - val_accuracy: 0.7966\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.5986 - accuracy: 0.8382 - val_loss: 0.6071 - val_accuracy: 0.8305\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5863 - accuracy: 0.8309 - val_loss: 0.5969 - val_accuracy: 0.8305\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5738 - accuracy: 0.8529 - val_loss: 0.5864 - val_accuracy: 0.8305\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 56ms/step - loss: 0.5621 - accuracy: 0.8529 - val_loss: 0.5756 - val_accuracy: 0.8305\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5507 - accuracy: 0.8529 - val_loss: 0.5649 - val_accuracy: 0.8305\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5388 - accuracy: 0.8529 - val_loss: 0.5545 - val_accuracy: 0.8136\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.5273 - accuracy: 0.8529 - val_loss: 0.5440 - val_accuracy: 0.8136\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.5161 - accuracy: 0.8529 - val_loss: 0.5338 - val_accuracy: 0.8305\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.5049 - accuracy: 0.8529 - val_loss: 0.5239 - val_accuracy: 0.8305\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.4940 - accuracy: 0.8529 - val_loss: 0.5142 - val_accuracy: 0.8305\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.4830 - accuracy: 0.8529 - val_loss: 0.5044 - val_accuracy: 0.8305\n",
      "Wall time: 3.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# fit the model\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cc4733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5043603777885437, 0.8305084705352783]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1d64a7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.50\n",
      "accuracy: 83.05%\n"
     ]
    }
   ],
   "source": [
    "# let's format this into a better output...\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d54e8e",
   "metadata": {},
   "source": [
    "# Wide and Deep Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3162dddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model: for multi-class\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Input(shape=22))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(50, activation='relu'))\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "350802be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "\n",
    "#Optimizer:\n",
    "adam = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fad723fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 367ms/step - loss: 0.7284 - accuracy: 0.4191 - val_loss: 0.4712 - val_accuracy: 0.8644\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.4316 - accuracy: 0.8456 - val_loss: 0.3535 - val_accuracy: 0.8475\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.3423 - accuracy: 0.8824 - val_loss: 0.3240 - val_accuracy: 0.8475\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.2872 - accuracy: 0.8824 - val_loss: 0.3029 - val_accuracy: 0.8475\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.2461 - accuracy: 0.9044 - val_loss: 0.2819 - val_accuracy: 0.8644\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 59ms/step - loss: 0.2060 - accuracy: 0.8971 - val_loss: 0.2618 - val_accuracy: 0.8644\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.1786 - accuracy: 0.9191 - val_loss: 0.2808 - val_accuracy: 0.8814\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1563 - accuracy: 0.9044 - val_loss: 0.3219 - val_accuracy: 0.8814\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.1417 - accuracy: 0.9191 - val_loss: 0.2677 - val_accuracy: 0.8644\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1225 - accuracy: 0.9191 - val_loss: 0.2589 - val_accuracy: 0.8644\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.1046 - accuracy: 0.9632 - val_loss: 0.2989 - val_accuracy: 0.8814\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.0847 - accuracy: 0.9559 - val_loss: 0.3076 - val_accuracy: 0.8983\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0769 - accuracy: 0.9779 - val_loss: 0.2945 - val_accuracy: 0.9153\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0649 - accuracy: 0.9779 - val_loss: 0.3000 - val_accuracy: 0.8983\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 58ms/step - loss: 0.0472 - accuracy: 0.9853 - val_loss: 0.2993 - val_accuracy: 0.8983\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.0387 - accuracy: 0.9926 - val_loss: 0.2541 - val_accuracy: 0.9153\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 52ms/step - loss: 0.0317 - accuracy: 0.9926 - val_loss: 0.2490 - val_accuracy: 0.9153\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0277 - accuracy: 0.9926 - val_loss: 0.2953 - val_accuracy: 0.9153\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9322\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 55ms/step - loss: 0.0181 - accuracy: 0.9926 - val_loss: 0.2871 - val_accuracy: 0.9153\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_test, y_test), \n",
    "                    epochs=20, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0889182c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2870670258998871, 0.9152542352676392]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "scores\n",
    "\n",
    "# In results, first is loss, second is accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "79e3ca7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.29\n",
      "accuracy: 91.53%\n"
     ]
    }
   ],
   "source": [
    "# extract the accuracy from model.evaluate\n",
    "\n",
    "print(\"%s: %.2f\" % (model.metrics_names[0], scores[0]))\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0eb8a",
   "metadata": {},
   "source": [
    "# RandomGridSearch with kernal initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eaee2a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikeras in c:\\users\\santo\\anaconda3\\lib\\site-packages (0.10.0)\n",
      "Requirement already satisfied: packaging>=0.21 in c:\\users\\santo\\anaconda3\\lib\\site-packages (from scikeras) (21.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in c:\\users\\santo\\anaconda3\\lib\\site-packages (from scikeras) (1.0.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\santo\\anaconda3\\lib\\site-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\users\\santo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.21.5)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\santo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\santo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\santo\\anaconda3\\lib\\site-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a7707cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 39.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = \"accuracy\"\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout):\n",
    "    ann = tf.keras.models.Sequential()\n",
    "    ann.add(keras.layers.Input(shape=22)),\n",
    "    for hidden_layer_size in hidden_layer_sizes:\n",
    "        model.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotUniform(), \n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\"))\n",
    "        model.add(keras.layers.Dropout(dropout))\n",
    "    ann.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "    ann.compile(loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    return ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ffdc5a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=64,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "55bb628f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bbd89f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 127ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F330B31820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001F330678670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 0s 75ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 83ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 78ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    }
   ],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring='accuracy', n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "062fa029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.005,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (100, 90),\n",
       " 'model__dropout': 0,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 20}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0dcd48b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.005, 'optimizer': 'sgd', 'model__hidden_layer_sizes': (100, 90), 'model__dropout': 0, 'epochs': 100, 'batch_size': 20}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3f6058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e4b502c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 4ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71        15\n",
      "           1       0.91      0.89      0.90        44\n",
      "\n",
      "    accuracy                           0.85        59\n",
      "   macro avg       0.80      0.81      0.80        59\n",
      "weighted avg       0.85      0.85      0.85        59\n",
      "\n",
      "Wall time: 151 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f487f",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ae3586",
   "metadata": {},
   "source": [
    "The Parkinson's disease dataset was used to train several predictive models, including SVM models with linear, rbf, and polynomial kernels, as well as logistic regression and decision tree models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92792c62",
   "metadata": {},
   "source": [
    "Among the SVM models, the Random search SVM Linear model and Grid search SVM Linear model had the highest accuracy, both achieving 94.9%. The polynomial kernel SVM model also performed well, achieving an accuracy of 93.2%.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3a6e0c",
   "metadata": {},
   "source": [
    "For logistic regression, the model without tuning had an accuracy of 93.2%, while the Randomized and Grid search models had accuracies of 89.8% and 89.8%, respectively. The decision tree models had lower accuracies, with the best models achieving accuracies of 86.4% and 83.1% for the Random search and Grid search models, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc86633",
   "metadata": {},
   "source": [
    "The MLPClassifier models outperformed all of the other models, with the Randomized search model achieving the highest accuracy at 96.6% and the Grid search model achieving an accuracy of 94.9%. The Keras models also performed well, with the Wide and Deep Network achieving an accuracy of 91% and the Deep Network achieving an accuracy of 83%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a46d2c3",
   "metadata": {},
   "source": [
    "\n",
    "Overall, the MLPClassifier models showed the best performance, followed by the SVM models and the Keras models. While the decision tree models had lower accuracies, they still showed some promise and could potentially be improved with further tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c34846",
   "metadata": {},
   "source": [
    "However, it's important to note that the performance of these models may vary depending on the specific features and characteristics of the dataset being used. It's also possible that with further experimentation and tuning of hyperparameters, other models could outperform the ones listed here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a41bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
