{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d9a984a",
   "metadata": {},
   "source": [
    "# Universal Bank -WE04 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f95444b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# set random seed to ensure that results are repeatable\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78394e7",
   "metadata": {},
   "source": [
    "# Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9835925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ubank=pd.read_csv(\"UniversalBank.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c238609",
   "metadata": {},
   "source": [
    "# Check the missing values by summing the total na's for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "849b8697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                    0\n",
       "Age                   0\n",
       "Experience            0\n",
       "Income                0\n",
       "ZIP Code              0\n",
       "Family                0\n",
       "CCAvg                 0\n",
       "Education             0\n",
       "Mortgage              0\n",
       "Personal Loan         0\n",
       "Securities Account    0\n",
       "CD Account            0\n",
       "Online                0\n",
       "CreditCard            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubank.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cce1c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4698\n",
       "1     302\n",
       "Name: CD Account, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubank['CD Account'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c5c295",
   "metadata": {},
   "source": [
    "# Dropping least important columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c10c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "ubank.drop(ubank.columns[[0,4]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf5e249",
   "metadata": {},
   "source": [
    "# Data split -train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b47092c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(ubank, test_size=0.3,random_state=1)\n",
    "target = 'CD Account'\n",
    "predictors = list(ubank.columns)\n",
    "predictors.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5e88399",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(train_df[predictors])\n",
    "\n",
    "\n",
    "train_X = scaler.transform(train_df[predictors]) \n",
    "train_y = train_df[target] \n",
    "\n",
    "test_X = scaler.transform(test_df[predictors])\n",
    "test_y = test_df[target] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb7251",
   "metadata": {},
   "source": [
    "# Logistic Regression using RandomSearch and Grid Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbbff3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.6708245243128964\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l2', 'max_iter': 851, 'C': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "910 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "280 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 457, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "340 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "290 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.66627907 0.66627907        nan 0.66627907 0.         0.66627907\n",
      " 0.66627907 0.66627907 0.66627907        nan        nan        nan\n",
      "        nan 0.31469345        nan 0.                nan        nan\n",
      " 0.66627907        nan 0.31469345 0.66627907        nan 0.37399577\n",
      " 0.66627907 0.66627907 0.         0.05940803        nan 0.\n",
      "        nan 0.67082452 0.66627907 0.66627907 0.37399577        nan\n",
      " 0.66627907 0.05940803 0.66627907 0.                nan 0.66627907\n",
      "        nan 0.05940803        nan        nan        nan 0.31469345\n",
      "        nan        nan        nan 0.         0.05940803        nan\n",
      "        nan 0.25095137        nan 0.37399577        nan        nan\n",
      " 0.05940803 0.66627907        nan        nan 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.25095137 0.66627907 0.\n",
      "        nan        nan 0.66627907 0.66627907 0.05940803 0.\n",
      "        nan 0.66627907 0.31469345        nan 0.66627907        nan\n",
      "        nan        nan 0.37399577 0.66627907 0.67082452 0.66627907\n",
      " 0.66627907 0.         0.66627907        nan        nan        nan\n",
      "        nan        nan 0.66627907 0.66627907        nan 0.66627907\n",
      "        nan 0.66627907 0.66627907 0.66627907 0.66627907 0.\n",
      " 0.67082452        nan        nan 0.66627907        nan        nan\n",
      "        nan 0.05940803 0.66627907 0.37399577 0.05940803        nan\n",
      "        nan        nan 0.66627907 0.66627907        nan        nan\n",
      " 0.67082452 0.66627907        nan 0.66627907 0.         0.05940803\n",
      " 0.31469345 0.66627907        nan 0.66627907        nan        nan\n",
      " 0.66627907        nan        nan 0.66627907 0.67082452 0.66627907\n",
      " 0.                nan        nan 0.66627907        nan 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907        nan 0.66627907 0.66627907\n",
      " 0.         0.66627907 0.66627907        nan 0.66627907 0.66627907\n",
      "        nan        nan 0.05940803        nan 0.66627907 0.66627907\n",
      " 0.67082452 0.66627907 0.25095137        nan        nan 0.66627907\n",
      " 0.66627907        nan        nan        nan 0.66627907 0.66627907\n",
      "        nan 0.         0.66627907 0.66627907 0.         0.66627907\n",
      "        nan 0.66627907        nan        nan 0.                nan\n",
      "        nan 0.66627907 0.67082452 0.66627907 0.                nan\n",
      " 0.66627907 0.66627907 0.66627907 0.         0.66627907 0.05940803\n",
      " 0.                nan        nan 0.66627907        nan        nan\n",
      " 0.05940803 0.66627907 0.66627907 0.66627907        nan        nan\n",
      " 0.66627907 0.67082452        nan 0.66627907 0.66627907 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907        nan 0.\n",
      "        nan 0.66627907 0.67082452        nan 0.         0.66627907\n",
      " 0.66627907        nan 0.25095137 0.05940803 0.05940803 0.\n",
      "        nan 0.66627907 0.66627907        nan 0.66627907        nan\n",
      " 0.66627907        nan 0.31469345 0.66627907 0.05940803 0.66627907\n",
      " 0.66627907 0.                nan 0.66627907 0.67082452 0.66627907\n",
      "        nan 0.         0.66627907 0.66627907 0.31469345        nan\n",
      " 0.         0.05940803 0.66627907        nan 0.66627907 0.37399577\n",
      " 0.66627907        nan 0.37399577 0.66627907 0.66627907 0.66627907\n",
      " 0.66627907        nan 0.66627907 0.66627907 0.67082452 0.66627907\n",
      " 0.66627907        nan        nan        nan        nan 0.66627907\n",
      " 0.                nan 0.66627907        nan 0.         0.\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.31469345        nan\n",
      " 0.                nan 0.25095137        nan 0.66627907        nan\n",
      " 0.66627907        nan        nan        nan 0.66627907        nan\n",
      " 0.66627907 0.66627907        nan 0.                nan        nan\n",
      " 0.66627907 0.66627907        nan 0.05940803 0.66627907 0.66627907\n",
      " 0.31469345 0.         0.66627907        nan 0.66627907 0.25095137\n",
      " 0.66627907        nan        nan 0.66627907 0.66627907 0.66627907\n",
      "        nan 0.66627907 0.37399577 0.66627907 0.66627907 0.\n",
      " 0.37399577        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.05940803 0.66627907 0.66627907 0.67082452\n",
      " 0.         0.66627907        nan 0.31469345 0.66627907        nan\n",
      "        nan 0.66627907 0.66627907 0.37399577 0.66627907        nan\n",
      "        nan        nan 0.         0.66627907 0.66627907 0.31469345\n",
      " 0.66627907 0.66627907        nan 0.                nan 0.66627907\n",
      " 0.66627907 0.66627907        nan        nan 0.66627907        nan\n",
      " 0.         0.66627907        nan 0.66627907 0.66627907 0.66627907\n",
      " 0.05940803        nan 0.31469345 0.05940803 0.05940803        nan\n",
      " 0.05940803 0.66627907        nan        nan 0.67082452 0.66627907\n",
      " 0.37399577 0.25095137 0.66627907        nan 0.66627907 0.66627907\n",
      " 0.66627907        nan 0.31469345        nan 0.66627907 0.05940803\n",
      " 0.66627907        nan 0.66627907 0.66627907        nan        nan\n",
      " 0.66627907        nan        nan 0.66627907        nan 0.66627907\n",
      " 0.25095137 0.66627907        nan 0.         0.66627907 0.66627907\n",
      " 0.66627907 0.66627907        nan 0.66627907        nan 0.66627907\n",
      " 0.66627907 0.66627907 0.66627907 0.66627907 0.66627907 0.31469345\n",
      " 0.66627907        nan 0.67082452        nan 0.66627907 0.66627907\n",
      " 0.66627907 0.                nan        nan 0.66627907        nan\n",
      " 0.66627907        nan 0.31469345        nan        nan 0.66627907\n",
      " 0.66627907        nan 0.66627907 0.37399577 0.66627907        nan\n",
      " 0.         0.66627907        nan 0.66627907        nan        nan\n",
      " 0.                nan 0.66627907 0.66627907 0.66627907 0.\n",
      "        nan        nan        nan 0.66627907        nan        nan\n",
      "        nan 0.37399577        nan        nan        nan 0.05940803\n",
      "        nan        nan 0.67082452 0.31469345        nan 0.66627907\n",
      " 0.66627907 0.66627907]\n",
      "  warnings.warn(\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [0.66664286 0.66664286        nan 0.66664286 0.         0.66664286\n",
      " 0.66664286 0.66664286 0.66664286        nan        nan        nan\n",
      "        nan 0.31846104        nan 0.                nan        nan\n",
      " 0.66664286        nan 0.31846104 0.66664286        nan 0.42005195\n",
      " 0.66664286 0.66664286 0.         0.05936364        nan 0.\n",
      "        nan 0.66892857 0.66664286 0.66664286 0.42005195        nan\n",
      " 0.66664286 0.05936364 0.66664286 0.                nan 0.66664286\n",
      "        nan 0.05936364        nan        nan        nan 0.31846104\n",
      "        nan        nan        nan 0.         0.05936364        nan\n",
      "        nan 0.25567532        nan 0.42005195        nan        nan\n",
      " 0.05936364 0.66664286        nan        nan 0.66664286 0.66664286\n",
      " 0.66664286 0.66664286 0.66664286 0.25567532 0.66664286 0.\n",
      "        nan        nan 0.66664286 0.66664286 0.05936364 0.\n",
      "        nan 0.66664286 0.3196039         nan 0.66664286        nan\n",
      "        nan        nan 0.42005195 0.66664286 0.66892857 0.66664286\n",
      " 0.66664286 0.         0.66664286        nan        nan        nan\n",
      "        nan        nan 0.66664286 0.66664286        nan 0.66664286\n",
      "        nan 0.66664286 0.66664286 0.66664286 0.66664286 0.\n",
      " 0.66892857        nan        nan 0.66664286        nan        nan\n",
      "        nan 0.05936364 0.66664286 0.42005195 0.05936364        nan\n",
      "        nan        nan 0.66664286 0.66664286        nan        nan\n",
      " 0.66892857 0.66664286        nan 0.66664286 0.         0.05936364\n",
      " 0.31846104 0.66664286        nan 0.66664286        nan        nan\n",
      " 0.66664286        nan        nan 0.66664286 0.66892857 0.66664286\n",
      " 0.                nan        nan 0.66664286        nan 0.66664286\n",
      " 0.66664286 0.66664286 0.66664286        nan 0.66664286 0.66664286\n",
      " 0.         0.66664286 0.66664286        nan 0.66664286 0.66664286\n",
      "        nan        nan 0.05936364        nan 0.66664286 0.66664286\n",
      " 0.66892857 0.66664286 0.25567532        nan        nan 0.66664286\n",
      " 0.66664286        nan        nan        nan 0.66664286 0.66664286\n",
      "        nan 0.         0.66664286 0.66664286 0.         0.66664286\n",
      "        nan 0.66664286        nan        nan 0.                nan\n",
      "        nan 0.66664286 0.66892857 0.66664286 0.                nan\n",
      " 0.66664286 0.66664286 0.66664286 0.         0.66664286 0.05936364\n",
      " 0.                nan        nan 0.66664286        nan        nan\n",
      " 0.05936364 0.66664286 0.66664286 0.66664286        nan        nan\n",
      " 0.66664286 0.66892857        nan 0.66664286 0.66664286 0.66664286\n",
      " 0.66664286 0.66664286 0.66664286 0.66664286        nan 0.\n",
      "        nan 0.66664286 0.66892857        nan 0.         0.66664286\n",
      " 0.66664286        nan 0.25567532 0.05936364 0.05936364 0.\n",
      "        nan 0.66664286 0.66664286        nan 0.66664286        nan\n",
      " 0.66664286        nan 0.3196039  0.66664286 0.05936364 0.66664286\n",
      " 0.66664286 0.                nan 0.66664286 0.66892857 0.66664286\n",
      "        nan 0.         0.66664286 0.66664286 0.3196039         nan\n",
      " 0.         0.05936364 0.66664286        nan 0.66664286 0.42005195\n",
      " 0.66664286        nan 0.42005195 0.66664286 0.66664286 0.66664286\n",
      " 0.66664286        nan 0.66664286 0.66664286 0.66892857 0.66664286\n",
      " 0.66664286        nan        nan        nan        nan 0.66664286\n",
      " 0.                nan 0.66664286        nan 0.         0.\n",
      " 0.66664286 0.66664286 0.66664286 0.66664286 0.31846104        nan\n",
      " 0.                nan 0.25567532        nan 0.66664286        nan\n",
      " 0.66664286        nan        nan        nan 0.66664286        nan\n",
      " 0.66664286 0.66664286        nan 0.                nan        nan\n",
      " 0.66664286 0.66664286        nan 0.05936364 0.66664286 0.66664286\n",
      " 0.31846104 0.         0.66664286        nan 0.66664286 0.25567532\n",
      " 0.66664286        nan        nan 0.66664286 0.66664286 0.66664286\n",
      "        nan 0.66664286 0.42005195 0.66664286 0.66664286 0.\n",
      " 0.42005195        nan        nan        nan        nan        nan\n",
      "        nan        nan 0.05936364 0.66664286 0.66664286 0.66892857\n",
      " 0.         0.66664286        nan 0.3196039  0.66664286        nan\n",
      "        nan 0.66664286 0.66664286 0.42005195 0.66664286        nan\n",
      "        nan        nan 0.         0.66664286 0.66664286 0.31846104\n",
      " 0.66664286 0.66664286        nan 0.                nan 0.66664286\n",
      " 0.66664286 0.66664286        nan        nan 0.66664286        nan\n",
      " 0.         0.66664286        nan 0.66664286 0.66664286 0.66664286\n",
      " 0.05936364        nan 0.31846104 0.05936364 0.05936364        nan\n",
      " 0.05936364 0.66664286        nan        nan 0.66892857 0.66664286\n",
      " 0.42005195 0.25567532 0.66664286        nan 0.66664286 0.66664286\n",
      " 0.66664286        nan 0.31846104        nan 0.66664286 0.05936364\n",
      " 0.66664286        nan 0.66664286 0.66664286        nan        nan\n",
      " 0.66664286        nan        nan 0.66664286        nan 0.66664286\n",
      " 0.25567532 0.66664286        nan 0.         0.66664286 0.66664286\n",
      " 0.66664286 0.66664286        nan 0.66664286        nan 0.66664286\n",
      " 0.66664286 0.66664286 0.66664286 0.66664286 0.66664286 0.31846104\n",
      " 0.66664286        nan 0.66892857        nan 0.66664286 0.66664286\n",
      " 0.66664286 0.                nan        nan 0.66664286        nan\n",
      " 0.66664286        nan 0.31846104        nan        nan 0.66664286\n",
      " 0.66664286        nan 0.66664286 0.42005195 0.66664286        nan\n",
      " 0.         0.66664286        nan 0.66664286        nan        nan\n",
      " 0.                nan 0.66664286 0.66664286 0.66664286 0.\n",
      "        nan        nan        nan 0.66664286        nan        nan\n",
      "        nan 0.42005195        nan        nan        nan 0.05936364\n",
      "        nan        nan 0.66892857 0.3196039         nan 0.66664286\n",
      " 0.66664286 0.66664286]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {'C':[0.001,0.01,0.1,1,10], # C is the regulization strength\n",
    "               'penalty':['l1', 'l2','elasticnet','none'],\n",
    "              'solver':['saga','liblinear'],\n",
    "              'max_iter': np.arange(500,1000)\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "lr = LogisticRegression()\n",
    "rand_search = RandomizedSearchCV(estimator = lr, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestlr = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73d5b928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1600 candidates, totalling 8000 fits\n",
      "The best recall score is 0.6708245243128964\n",
      "... with parameters: {'C': 0.09999999999999998, 'max_iter': 451, 'penalty': 'l2', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "4000 fits failed out of a total of 8000.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4000 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1464, in fit\n",
      "    raise ValueError(\"Penalty term must be positive; got (C=%r)\" % self.C)\n",
      "ValueError: Penalty term must be positive; got (C=-0.9)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan ... 0.67082452 0.67082452 0.67082452]\n",
      "  warnings.warn(\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan        nan        nan ... 0.66892857 0.66892857 0.66892857]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "best_penality = rand_search.best_params_['penalty']\n",
    "best_solver = rand_search.best_params_['solver']\n",
    "min_regulization_strength=rand_search.best_params_['C']\n",
    "min_iter = rand_search.best_params_['max_iter']\n",
    "\n",
    "#Using the best parameters from the Random Search to use as range for the parameters to do the grid search\n",
    "param_grid = {\n",
    "    \n",
    "    'C':np.arange(min_regulization_strength-1,min_regulization_strength+1), \n",
    "               'penalty':[best_penality],\n",
    "              'solver':[best_solver],\n",
    "              'max_iter': np.arange(min_iter-400,min_iter+400)\n",
    "}\n",
    "\n",
    "logreg =  LogisticRegression()\n",
    "grid_search = GridSearchCV(estimator = logreg, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, # n_jobs=-1 will utilize all available CPUs \n",
    "                return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestlogreg = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3ca1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy=0.9780000 Precision=1.0000000 Recall=0.6024096 F1=0.7518797\n"
     ]
    }
   ],
   "source": [
    "c_matrix = confusion_matrix(test_y, grid_search.predict(test_X))\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "print(f\"Accuracy={(TP+TN)/(TP+TN+FP+FN):.7f} Precision={TP/(TP+FP):.7f} Recall={TP/(TP+FN):.7f} F1={2*TP/(2*TP+FP+FN):.7f}\")\n",
    "Recall_lr={TP/(TP+FN)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77f04016",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"logistic using random & grid search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817da2d6",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2d7c0d",
   "metadata": {},
   "source": [
    "# svm with linear kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c81611f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_lin_model = SVC(kernel=\"linear\",probability=True)\n",
    "_ = svm_lin_model.fit(train_X, np.ravel(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58f0291a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                              lin svm  0.978000   1.000000  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.751880  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_lin_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"lin svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365d500b",
   "metadata": {},
   "source": [
    "# svm with rbf kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "26a54ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf_model = SVC(kernel=\"rbf\", C=10, gamma='scale',probability=True)\n",
    "_ = svm_rbf_model.fit(train_X, np.ravel(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f33e5fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                              lin svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.751880  \n",
       "0  0.724638  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = svm_rbf_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"rbf svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b786e6f",
   "metadata": {},
   "source": [
    "# svm with poly kernel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "63fb5a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_poly_model = SVC(kernel=\"poly\",probability=True, degree=3, coef0=1, C=10)\n",
    "_ = svm_poly_model.fit(train_X, np.ravel(train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1b7e23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = svm_poly_model.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"poly svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db471db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                              lin svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "0                             poly svm  0.970000   0.806452  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.751880  \n",
       "0  0.724638  \n",
       "0  0.689655  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd482302",
   "metadata": {},
   "source": [
    "# random search in SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59a17bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 16 is smaller than n_iter=500. Running 16 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The best precision score is 1.0\n",
      "... with parameters: {'kernel': 'poly', 'gamma': 0.1, 'C': 0.1}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.1,1,10,100],\n",
    "    'gamma':[1,0.1,0.01,0.001],\n",
    "    'kernel':['poly']\n",
    "    \n",
    "}\n",
    "\n",
    "SVM_R_out = SVC()\n",
    "rand_search = RandomizedSearchCV(estimator = SVM_R_out, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "18ead68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds = rand_search.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"rand_poly_svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7504fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                              lin svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "0                             poly svm  0.970000   0.806452  0.602410   \n",
       "0                        rand_poly_svm  0.978000   1.000000  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.751880  \n",
       "0  0.724638  \n",
       "0  0.689655  \n",
       "0  0.751880  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ed55e",
   "metadata": {},
   "source": [
    "# grid search in SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59b6ed26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The best precision score is 1.0\n",
      "... with parameters: {'C': 0.1, 'gamma': 0.1, 'kernel': 'poly'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "score_measure = \"precision\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'C':[0.1,1,10,100],\n",
    "    'gamma':[1,0.1,0.01,0.001],\n",
    "    'kernel':['poly']\n",
    "    \n",
    "}\n",
    "\n",
    "SVM_G_out = SVC()\n",
    "grid_search = GridSearchCV(estimator = SVM_G_out, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X, train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3676b10c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic using random &amp; grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm using Random &amp; Grid search</td>\n",
       "      <td>0.955333</td>\n",
       "      <td>0.586957</td>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.617143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lin svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rbf svm</td>\n",
       "      <td>0.974667</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>poly svm</td>\n",
       "      <td>0.970000</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.689655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rand_poly_svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>grid_poly_svm</td>\n",
       "      <td>0.978000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.751880</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 model  Accuracy  Precision    Recall  \\\n",
       "0  logistic using random & grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0       svm using Random & Grid search  0.955333   0.586957  0.650602   \n",
       "0                              lin svm  0.978000   1.000000  0.602410   \n",
       "0                              rbf svm  0.974667   0.909091  0.602410   \n",
       "0                             poly svm  0.970000   0.806452  0.602410   \n",
       "0                        rand_poly_svm  0.978000   1.000000  0.602410   \n",
       "0                        grid_poly_svm  0.978000   1.000000  0.602410   \n",
       "\n",
       "         F1  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.617143  \n",
       "0  0.751880  \n",
       "0  0.724638  \n",
       "0  0.689655  \n",
       "0  0.751880  \n",
       "0  0.751880  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds = grid_search.predict(test_X)\n",
    "c_matrix = confusion_matrix(test_y, model_preds)\n",
    "TP = c_matrix[1][1]\n",
    "TN = c_matrix[0][0]\n",
    "FP = c_matrix[0][1]\n",
    "FN = c_matrix[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"grid_poly_svm\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])\n",
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810d88f",
   "metadata": {},
   "source": [
    "#  Decision Trees  using RandomSearch and GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d4fdb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 500 candidates, totalling 2500 fits\n",
      "The best recall score is 0.6710359408033826\n",
      "... with parameters: {'min_samples_split': 34, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_leaf_nodes': 39, 'max_depth': 21, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 2500.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.30591966 0.29682875 0.63890063 0.29682875 0.51638478\n",
      " 0.58002114 0.54334038 0.31057082 0.56162791 0.63890063 0.56162791\n",
      " 0.29682875 0.56617336 0.63890063 0.54799154 0.66649049 0.64799154\n",
      " 0.57547569 0.63890063 0.63890063 0.57547569 0.63890063 0.5345666\n",
      " 0.57547569 0.59830867 0.54788584 0.31057082        nan 0.53890063\n",
      " 0.54799154 0.57547569 0.63890063 0.51638478 0.30591966 0.49788584\n",
      " 0.63890063 0.30591966 0.59830867 0.63890063 0.50274841 0.29682875\n",
      " 0.63890063 0.63890063 0.47526427 0.55729387 0.63890063 0.57547569\n",
      " 0.59344609 0.59830867 0.57547569 0.59830867 0.59344609 0.29682875\n",
      " 0.51638478 0.52526427 0.63890063 0.65718816 0.30591966 0.59376321\n",
      " 0.67103594 0.57547569 0.63890063 0.57547569 0.32420719 0.\n",
      " 0.57547569 0.56617336 0.31955603 0.56183932 0.54334038 0.63890063\n",
      " 0.48890063 0.54799154 0.54799154 0.57547569 0.59830867 0.63890063\n",
      " 0.66649049 0.29682875 0.65708245 0.57547569 0.57547569 0.52061311\n",
      " 0.52061311 0.50274841 0.56183932 0.29682875 0.52526427 0.57547569\n",
      " 0.61649049 0.63890063 0.59344609 0.59344609 0.64799154 0.57547569\n",
      " 0.63890063 0.29682875 0.30137421 0.63890063 0.63890063 0.59830867\n",
      " 0.53890063 0.59830867        nan 0.53890063 0.54788584 0.59344609\n",
      " 0.31955603 0.63890063 0.59830867 0.66649049 0.54799154 0.63890063\n",
      " 0.56162791 0.59830867 0.63890063 0.56162791 0.56162791 0.64799154\n",
      " 0.57547569 0.29682875 0.63890063 0.57547569        nan 0.47526427\n",
      " 0.64809725 0.27854123 0.59830867 0.5255814  0.63890063 0.56617336\n",
      " 0.42399577 0.59344609 0.53890063 0.59830867 0.         0.63890063\n",
      " 0.65264271 0.65718816 0.30591966 0.54788584 0.63890063 0.59344609\n",
      " 0.63890063 0.48879493 0.54334038 0.57547569 0.54799154 0.28773784\n",
      " 0.56183932 0.63890063 0.63890063 0.63890063 0.65708245 0.\n",
      " 0.6435518  0.66649049 0.32420719 0.         0.59376321 0.59830867\n",
      " 0.59830867 0.26035941 0.54334038 0.59830867 0.31955603 0.63890063\n",
      " 0.63890063 0.46955603 0.63890063 0.63890063 0.54788584 0.29682875\n",
      " 0.48890063 0.58002114 0.46955603 0.56162791 0.64799154 0.46955603\n",
      " 0.65718816 0.63890063 0.63890063 0.59344609 0.63890063 0.63890063\n",
      " 0.29682875 0.31057082 0.56162791 0.59830867 0.57547569 0.63890063\n",
      " 0.59376321 0.54334038 0.37864693 0.51638478 0.54799154 0.53890063\n",
      " 0.56162791 0.54799154 0.52526427        nan 0.56162791 0.54788584\n",
      " 0.57547569 0.57547569 0.28773784 0.63890063 0.59830867 0.56617336\n",
      " 0.58921776 0.59376321 0.63890063 0.63890063 0.29682875 0.56162791\n",
      " 0.59344609 0.63890063 0.63890063 0.52526427 0.57547569 0.53890063\n",
      " 0.59376321 0.37864693 0.59830867 0.58002114 0.56162791 0.54788584\n",
      " 0.29682875 0.63890063 0.63890063 0.27399577        nan 0.50274841\n",
      " 0.52071882 0.56162791 0.46046512 0.59830867 0.29682875 0.29682875\n",
      " 0.63890063 0.32420719 0.63890063 0.29682875 0.5255814  0.63890063\n",
      " 0.59344609 0.27399577 0.27854123 0.65718816 0.63890063 0.31057082\n",
      " 0.57547569 0.32420719 0.59830867        nan 0.63890063 0.63890063\n",
      " 0.29682875 0.30591966 0.56162791 0.54788584 0.63890063 0.46955603\n",
      " 0.31955603        nan 0.27399577 0.33319239 0.51638478 0.63890063\n",
      " 0.57547569 0.57547569 0.30591966 0.63890063 0.63890063 0.56162791\n",
      " 0.48890063 0.66649049 0.59830867 0.30591966 0.56162791 0.29682875\n",
      " 0.59830867 0.32420719 0.59344609 0.52526427 0.63890063 0.27399577\n",
      " 0.63890063 0.29682875 0.29682875 0.63890063 0.57547569 0.5255814\n",
      " 0.56162791 0.63890063 0.52526427 0.53890063 0.31057082 0.59830867\n",
      " 0.63890063 0.54788584 0.63890063 0.54799154 0.59376321 0.59344609\n",
      " 0.27399577 0.63890063 0.59344609 0.51638478 0.56162791 0.30591966\n",
      " 0.29682875 0.59344609 0.29682875 0.59830867 0.59830867 0.53890063\n",
      " 0.6435518  0.33319239 0.56162791 0.63890063 0.53890063 0.64799154\n",
      " 0.29682875 0.27399577 0.31955603 0.59344609 0.56162791 0.59830867\n",
      " 0.63890063 0.         0.52970402 0.32420719 0.56162791 0.5255814\n",
      " 0.33319239 0.63890063 0.54799154 0.27399577 0.59344609 0.63890063\n",
      " 0.59830867 0.63890063 0.57547569 0.63890063 0.29682875 0.\n",
      " 0.63890063 0.64799154 0.50274841 0.59830867 0.29682875 0.32420719\n",
      " 0.63890063 0.64799154 0.59830867 0.63890063 0.62536998 0.63890063\n",
      " 0.63890063 0.63890063 0.58002114 0.57547569 0.59830867 0.33319239\n",
      " 0.31955603 0.29682875 0.57547569 0.59830867 0.29682875 0.57547569\n",
      " 0.4602537  0.56162791 0.64809725 0.54788584 0.50697674 0.30591966\n",
      " 0.63890063 0.63890063 0.63890063 0.54799154 0.         0.54334038\n",
      " 0.58002114 0.64809725 0.29682875 0.59830867 0.32420719 0.54799154\n",
      " 0.63890063 0.63890063 0.59830867 0.56162791 0.63890063 0.27854123\n",
      " 0.54799154 0.31955603 0.54788584 0.37864693 0.63890063 0.33319239\n",
      " 0.30591966 0.46617336 0.28773784 0.57547569 0.63890063 0.4602537\n",
      " 0.27399577 0.59830867 0.63890063 0.57547569 0.64799154 0.46955603\n",
      " 0.4602537  0.62536998 0.32420719 0.58002114 0.         0.37864693\n",
      " 0.63890063 0.59830867 0.59830867 0.67082452 0.56162791 0.59344609\n",
      " 0.57547569 0.32420719 0.         0.63890063 0.31955603 0.57547569\n",
      " 0.56649049 0.26501057 0.29682875 0.63890063 0.59830867 0.59830867\n",
      " 0.29682875 0.53890063 0.29682875 0.59344609 0.37864693 0.59830867\n",
      " 0.53890063 0.63890063 0.59344609 0.59830867 0.63890063 0.53890063\n",
      " 0.32420719 0.63890063 0.57547569 0.64809725 0.63890063 0.55729387\n",
      " 0.         0.63890063 0.58002114 0.63890063 0.32420719 0.31955603\n",
      " 0.65718816 0.57547569 0.57547569 0.56617336 0.27864693 0.63890063\n",
      " 0.27399577 0.63890063 0.63890063 0.31057082 0.59344609 0.63890063\n",
      " 0.63890063 0.31057082 0.54788584 0.63890063 0.29682875 0.\n",
      " 0.52526427 0.57547569 0.47526427 0.2922833  0.53890063 0.63890063\n",
      " 0.59344609        nan 0.57547569 0.56162791 0.66627907 0.56162791\n",
      " 0.63890063 0.64799154 0.66173362 0.5255814  0.29682875 0.66649049\n",
      " 0.54788584 0.63890063]\n",
      "  warnings.warn(\n",
      "C:\\Users\\santo\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.37897403 0.33905844 0.63924675 0.33905844 0.49538312\n",
      " 0.56624026 0.53538961 0.38805844 0.6061039  0.63924675 0.6061039\n",
      " 0.33905844 0.59238961 0.63924675 0.56038961 0.65181169 0.65524675\n",
      " 0.55595455 0.64724675 0.63924675 0.55595455 0.63924675 0.51938312\n",
      " 0.55595455 0.59818182 0.53767532 0.38805844        nan 0.55924675\n",
      " 0.58324675 0.55595455 0.64838961 0.49766883 0.37897403 0.4931039\n",
      " 0.63924675 0.37897403 0.59818182 0.63924675 0.50452597 0.33905844\n",
      " 0.63924675 0.63924675 0.51353247 0.53995455 0.63924675 0.55138312\n",
      " 0.62438961 0.59818182 0.55595455 0.59818182 0.62438961 0.33905844\n",
      " 0.49538312 0.53753247 0.63924675 0.66663636 0.37897403 0.58675325\n",
      " 0.6906039  0.55138312 0.63924675 0.55595455 0.41091558 0.\n",
      " 0.55595455 0.59238961 0.37783117 0.54681169 0.53538961 0.63924675\n",
      " 0.55924675 0.58324675 0.56038961 0.55595455 0.59818182 0.63924675\n",
      " 0.65181169 0.33905844 0.66324675 0.55595455 0.55595455 0.51253247\n",
      " 0.51253247 0.50452597 0.54566883 0.33905844 0.53753247 0.55595455\n",
      " 0.63466883 0.63924675 0.62438961 0.62438961 0.65638961 0.55595455\n",
      " 0.63924675 0.33905844 0.36868831 0.63924675 0.63924675 0.59818182\n",
      " 0.55924675 0.59818182        nan 0.55924675 0.5411039  0.62438961\n",
      " 0.37783117 0.63924675 0.59818182 0.65181169 0.56038961 0.63924675\n",
      " 0.6061039  0.59818182 0.63924675 0.6061039  0.6061039  0.65524675\n",
      " 0.55595455 0.33905844 0.63924675 0.55595455        nan 0.53638961\n",
      " 0.66092208 0.30711688 0.59818182 0.54675325 0.63924675 0.59238961\n",
      " 0.43854545 0.62438961 0.55924675 0.59818182 0.         0.64838961\n",
      " 0.6655     0.66664286 0.37897403 0.5411039  0.63924675 0.62438961\n",
      " 0.63924675 0.4851039  0.53538961 0.55595455 0.58324675 0.35954545\n",
      " 0.54681169 0.63924675 0.63924675 0.63924675 0.66324675 0.\n",
      " 0.65406494 0.65181169 0.41091558 0.         0.58675325 0.59818182\n",
      " 0.59818182 0.28768831 0.53538961 0.59818182 0.37783117 0.63924675\n",
      " 0.63924675 0.52525974 0.63924675 0.63924675 0.5411039  0.33905844\n",
      " 0.55924675 0.56624026 0.52525974 0.6061039  0.65524675 0.52525974\n",
      " 0.67349351 0.63924675 0.63924675 0.62438961 0.63924675 0.63924675\n",
      " 0.33905844 0.38805844 0.6061039  0.59818182 0.55595455 0.63924675\n",
      " 0.58675325 0.53538961 0.42811688 0.49424026 0.56038961 0.55924675\n",
      " 0.6061039  0.58324675 0.53753247        nan 0.6061039  0.53767532\n",
      " 0.55595455 0.55595455 0.35954545 0.63924675 0.59818182 0.59238961\n",
      " 0.61866883 0.58675325 0.63924675 0.63924675 0.33905844 0.6061039\n",
      " 0.62438961 0.64724675 0.63924675 0.53753247 0.55595455 0.55924675\n",
      " 0.58675325 0.42811688 0.59818182 0.56624026 0.6061039  0.53767532\n",
      " 0.33905844 0.64838961 0.63924675 0.29683117        nan 0.50452597\n",
      " 0.57753247 0.6061039  0.49334416 0.59818182 0.33905844 0.33905844\n",
      " 0.63924675 0.41091558 0.63924675 0.33905844 0.54675325 0.63924675\n",
      " 0.62438961 0.29683117 0.30711688 0.66663636 0.63924675 0.38805844\n",
      " 0.55595455 0.41091558 0.59818182        nan 0.63924675 0.63924675\n",
      " 0.33905844 0.37897403 0.6061039  0.5411039  0.63924675 0.52525974\n",
      " 0.37783117        nan 0.29683117 0.38697403 0.49766883 0.63924675\n",
      " 0.55595455 0.55595455 0.37897403 0.63924675 0.63924675 0.6061039\n",
      " 0.55924675 0.65181169 0.59818182 0.37897403 0.6061039  0.33905844\n",
      " 0.59818182 0.41091558 0.62438961 0.53753247 0.63924675 0.29683117\n",
      " 0.63924675 0.33905844 0.33905844 0.63924675 0.55595455 0.54675325\n",
      " 0.6061039  0.63924675 0.53753247 0.55924675 0.38805844 0.59818182\n",
      " 0.64724675 0.5411039  0.63924675 0.56038961 0.58675325 0.62438961\n",
      " 0.29683117 0.63924675 0.62438961 0.49424026 0.6061039  0.37897403\n",
      " 0.33905844 0.62438961 0.33905844 0.59818182 0.59818182 0.55924675\n",
      " 0.65406494 0.38697403 0.6061039  0.63924675 0.55924675 0.65524675\n",
      " 0.33905844 0.29683117 0.37783117 0.62438961 0.6061039  0.59818182\n",
      " 0.63924675 0.         0.52738961 0.41091558 0.6061039  0.54675325\n",
      " 0.38697403 0.63924675 0.58324675 0.29683117 0.62438961 0.63924675\n",
      " 0.59818182 0.63924675 0.55595455 0.63924675 0.33905844 0.\n",
      " 0.63924675 0.65524675 0.50452597 0.59818182 0.33905844 0.41091558\n",
      " 0.63924675 0.65638961 0.59818182 0.63924675 0.66433117 0.63924675\n",
      " 0.63924675 0.63924675 0.56624026 0.55595455 0.59818182 0.38697403\n",
      " 0.37783117 0.33905844 0.55138312 0.59818182 0.33905844 0.55595455\n",
      " 0.46027273 0.6061039  0.66092208 0.5411039  0.50338961 0.37897403\n",
      " 0.64724675 0.63924675 0.63924675 0.58324675 0.         0.53538961\n",
      " 0.56624026 0.66092208 0.33905844 0.59818182 0.41091558 0.58324675\n",
      " 0.63924675 0.63924675 0.59818182 0.6061039  0.63924675 0.30711688\n",
      " 0.56038961 0.37783117 0.53767532 0.42811688 0.63924675 0.38697403\n",
      " 0.37897403 0.51238961 0.35954545 0.55595455 0.63924675 0.46027273\n",
      " 0.29683117 0.59818182 0.63924675 0.55595455 0.65638961 0.52525974\n",
      " 0.46027273 0.66433117 0.41091558 0.56624026 0.         0.42811688\n",
      " 0.63924675 0.59818182 0.59818182 0.68831169 0.6061039  0.62438961\n",
      " 0.55595455 0.41091558 0.         0.63924675 0.37783117 0.55595455\n",
      " 0.57181169 0.31268831 0.33905844 0.63924675 0.59818182 0.59818182\n",
      " 0.33905844 0.55924675 0.33905844 0.62438961 0.42811688 0.59818182\n",
      " 0.55924675 0.63924675 0.62438961 0.59818182 0.64724675 0.55924675\n",
      " 0.41091558 0.63924675 0.55595455 0.67235065 0.63924675 0.53995455\n",
      " 0.         0.64724675 0.56624026 0.63924675 0.41091558 0.37783117\n",
      " 0.67921429 0.55138312 0.55595455 0.56847403 0.32183117 0.63924675\n",
      " 0.29683117 0.63924675 0.64838961 0.38805844 0.62438961 0.63924675\n",
      " 0.63924675 0.38805844 0.5411039  0.63924675 0.33905844 0.\n",
      " 0.53753247 0.55595455 0.53638961 0.32762987 0.55924675 0.63924675\n",
      " 0.62438961        nan 0.55138312 0.6061039  0.6735     0.6061039\n",
      " 0.63924675 0.65524675 0.72029221 0.54675325 0.33905844 0.65181169\n",
      " 0.53767532 0.63924675]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#decision tree classifier\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(1,42),  \n",
    "    'min_samples_leaf': np.arange(1,42),\n",
    "    'min_impurity_decrease': np.arange(0.0001, 0.01, 0.0005),\n",
    "    'max_leaf_nodes': np.arange(5, 42), \n",
    "    'max_depth': np.arange(1,42), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "rand_search = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = rand_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {rand_search.best_score_}\")\n",
    "print(f\"... with parameters: {rand_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = rand_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02e8943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "The best recall score is 0.6893234672304439\n",
      "... with parameters: {'criterion': 'entropy', 'max_depth': 39, 'max_leaf_nodes': 39, 'min_impurity_decrease': 0.001, 'min_samples_leaf': 3, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': np.arange(3,6),  \n",
    "    'min_samples_leaf': np.arange(3,6),\n",
    "    'min_impurity_decrease': np.arange(0.0009, 0.0012,0.0001),\n",
    "    'max_leaf_nodes': np.arange(36,40), \n",
    "    'max_depth': np.arange(39,42), \n",
    "    'criterion': ['entropy'],\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier()\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(train_X,train_y)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")\n",
    "\n",
    "bestRecallTree = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab6a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "From the analysis we can say that decision tree had good scope and the best fit among the models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
